{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end machine learning project\n",
    "This notebook is a simplified version of the intro ML project presented by Aurelion Geron in pages 37-85.  \n",
    "Original source: https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### start with importing our Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sci-kit learn is our one-stop shop for machine learning!\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>-119.01</td>\n",
       "      <td>36.06</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>1.6812</td>\n",
       "      <td>47700.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>-119.46</td>\n",
       "      <td>35.14</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2943.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>2.5313</td>\n",
       "      <td>45800.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>-122.44</td>\n",
       "      <td>37.80</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>3.4801</td>\n",
       "      <td>500001.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>-118.72</td>\n",
       "      <td>34.28</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>5.7376</td>\n",
       "      <td>218600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>-121.93</td>\n",
       "      <td>36.62</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2351.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>3.7250</td>\n",
       "      <td>278000.0</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "20046    -119.01     36.06                25.0       1505.0             NaN   \n",
       "3024     -119.46     35.14                30.0       2943.0             NaN   \n",
       "15663    -122.44     37.80                52.0       3830.0             NaN   \n",
       "20484    -118.72     34.28                17.0       3051.0             NaN   \n",
       "9814     -121.93     36.62                34.0       2351.0             NaN   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "20046      1392.0       359.0         1.6812             47700.0   \n",
       "3024       1565.0       584.0         2.5313             45800.0   \n",
       "15663      1310.0       963.0         3.4801            500001.0   \n",
       "20484      1705.0       495.0         5.7376            218600.0   \n",
       "9814       1063.0       428.0         3.7250            278000.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "20046          INLAND  \n",
       "3024           INLAND  \n",
       "15663        NEAR BAY  \n",
       "20484       <1H OCEAN  \n",
       "9814       NEAR OCEAN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the dataset\n",
    "filepath = Path.joinpath(Path.cwd(), 'data', 'housing.csv')\n",
    "housing = pd.read_csv(filepath)\n",
    "housing.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide what is our variable of interest (this is the item we want to predict, aka the Dependent Variable, labels, or target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     20640.000000\n",
       "mean     206855.816909\n",
       "std      115395.615874\n",
       "min       14999.000000\n",
       "25%      119600.000000\n",
       "50%      179700.000000\n",
       "75%      264725.000000\n",
       "max      500001.000000\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['median_house_value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the story of one row?\n",
    "\"In this chapter we chose the California Housing Prices dataset from the StatLib repository2 (see Figure 2-1). This dataset was based on data from the 1990 California census. It is not exactly recent (you could still afford a nice house in the Bay Area at the time), but it has many qualities for learning, so we will pretend it is recent data. We also added a categorical attribute and removed a few features for teaching purposes.\" \n",
    "\n",
    "\"Each row represents one district. There are 10 attributes (you can see the first 6 in the screenshot): longitude, latitude, housing_median_age, total_rooms, total_bed rooms, population, households, median_income, median_house_value, and ocean_proximity.\"  \n",
    "-- Geron, pg. 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean        35.631861\n",
       "std          2.135952\n",
       "min         32.540000\n",
       "25%         33.930000\n",
       "50%         34.260000\n",
       "75%         37.710000\n",
       "max         41.950000\n",
       "Name: latitude, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['latitude'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean      -119.569704\n",
       "std          2.003532\n",
       "min       -124.350000\n",
       "25%       -121.800000\n",
       "50%       -118.490000\n",
       "75%       -118.010000\n",
       "max       -114.310000\n",
       "Name: longitude, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['longitude'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean         3.870671\n",
       "std          1.899822\n",
       "min          0.499900\n",
       "25%          2.563400\n",
       "50%          3.534800\n",
       "75%          4.743250\n",
       "max         15.000100\n",
       "Name: median_income, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['median_income'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean        28.639486\n",
       "std         12.585558\n",
       "min          1.000000\n",
       "25%         18.000000\n",
       "50%         29.000000\n",
       "75%         37.000000\n",
       "max         52.000000\n",
       "Name: housing_median_age, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['housing_median_age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean      2635.763081\n",
       "std       2181.615252\n",
       "min          2.000000\n",
       "25%       1447.750000\n",
       "50%       2127.000000\n",
       "75%       3148.000000\n",
       "max      39320.000000\n",
       "Name: total_rooms, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['total_rooms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean      1425.476744\n",
       "std       1132.462122\n",
       "min          3.000000\n",
       "25%        787.000000\n",
       "50%       1166.000000\n",
       "75%       1725.000000\n",
       "max      35682.000000\n",
       "Name: population, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['population'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean       499.539680\n",
       "std        382.329753\n",
       "min          1.000000\n",
       "25%        280.000000\n",
       "50%        409.000000\n",
       "75%        605.000000\n",
       "max       6082.000000\n",
       "Name: households, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['households'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create income categories\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     822\n",
       "2    6581\n",
       "3    7236\n",
       "4    3639\n",
       "5    2362\n",
       "Name: income_cat, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing[\"income_cat\"].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some additional variables\n",
    "housing[\"rooms_per_hhold\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"pop_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean         5.429000\n",
       "std          2.474173\n",
       "min          0.846154\n",
       "25%          4.440716\n",
       "50%          5.229129\n",
       "75%          6.052381\n",
       "max        141.909091\n",
       "Name: rooms_per_hhold, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing[\"rooms_per_hhold\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean         3.070655\n",
       "std         10.386050\n",
       "min          0.692308\n",
       "25%          2.429741\n",
       "50%          2.818116\n",
       "75%          3.282261\n",
       "max       1243.333333\n",
       "Name: pop_per_household, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing[\"pop_per_household\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot Encoding\n",
    "\"This is called one-hot encoding, because only one attribute will be equal to 1 (hot), while the others will be 0 (cold).\" - Geron, pg. 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['ocean_proximity'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for ocean proximity\n",
    "# Note: this is also called \"one-hot encoding\"\n",
    "housing=pd.get_dummies(housing, columns = ['ocean_proximity'], prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the variables?\n",
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rid of missing data\n",
    "Geron actually shows multiple options here (such as imputing the median) but we're just going to drop all rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn cannot handle missing data. we're just doing to drop it\n",
    "print(len(housing))\n",
    "print(housing.isnull().sum())\n",
    "housing.dropna(axis=1, inplace=True)\n",
    "print(len(housing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The only way to know how well a model will generalize to new cases is to actually try it out on new cases. One way to do that is to put your model in production and moni‐ tor how well it performs. This works well, but if your model is horribly bad, your users will complain—not the best idea.\n",
    "A better option is to split your data into two sets: the training set and the test set. As these names imply, you train your model using the training set, and you test it using the test set. The error rate on new cases is called the generalization error (or out-of- sample error), and by evaluating your model on the test set, you get an estimate of this error. This value tells you how well your model will perform on instances it has never seen before.\"  -- Geron, pg. 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split your data into features (X) and labels (y).\n",
    "y = housing[\"median_house_value\"].copy()\n",
    "# We drop one of the 'ocean_proximity' categories so that the coefficients will be interpretable\n",
    "X = housing.drop([\"median_house_value\",'<1H OCEAN'], axis=1)\n",
    "# Compare their shapes.\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, split both X and y data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                       test_size=0.2, \n",
    "                                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the shapes to confirm this did what you wanted.\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "\"One of the most important transformations you need to apply to your data is feature scaling. With few exceptions, Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales. This is the case for the hous‐ ing data: the total number of rooms ranges from about 6 to 39,320, while the median incomes only range from 0 to 15. Note that scaling the target values is generally not required.\n",
    "There are two common ways to get all attributes to have the same scale: min-max scaling (i.e., normalization) and standardization.\"  -- Geron, pg. 72\n",
    "\n",
    "\"Standardization is quite different: first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation so that the resulting distribution has unit variance. Unlike min-max scaling, standardization does not bound values to a specific range, which may be a problem for some algo‐ rithms (e.g., neural networks often expect an input value ranging from 0 to 1). However, standardization is much less affected by outliers. For example, suppose a district had a median income equal to 100 (by mistake). Min-max scaling would then crush all the other values from 0–15 down to 0–0.15, whereas standardization would not be much affected. Scikit-Learn provides a transformer called StandardScaler for standardization.\"  -- Geron, pg. 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the numeric variables in my dataset?\n",
    "X_train.describe().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Geron includes `median_house_value` in his scaling, but I do not. It's not actually necessary to scale your dependent variable (i.e., your target) and leaving it in the original metric makes the results a lot easier to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### One type of feature scaling: Standardization\n",
    "take a look at pages 72-73 in the Geron Aurelion book.\n",
    "One of the most important transformations you need to apply to your data is feature scaling. With few exceptions, Machine Learning algorithms don't perform well when the input numerical attributes have very different scales.  \n",
    "https://datascience.stackexchange.com/questions/27615/should-we-apply-normalization-to-test-data-as-well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The following code only works because we dropped missing data earlier. This is pretty common in `sklearn` -- either drop or impute missing values at the start of your analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Instantiate\" the scaler (create an instance of the sklearn class)\n",
    "std_scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Fit' the scaler to our X_train data\n",
    "std_scaler = std_scaler.fit(X_train)\n",
    "std_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scaler to transform the dataset\n",
    "X_train_scaled = std_scaler.transform(X_train)\n",
    "X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scaler to transform the dataset\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "X_test_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local instance of the sklearn class\n",
    "lin_reg = LinearRegression(fit_intercept=True)\n",
    "lin_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your instance to the training dataset\n",
    "lin_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the intercept and coefficients\n",
    "print(lin_reg.intercept_)\n",
    "print(lin_reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Attributes' is another name for our list of features (aka predictors, independent variables)\n",
    "attributes=X_test.columns\n",
    "print(attributes)\n",
    "# 'Feature importances' is another name for our coefficients (ie., the impace of each feature on the outcome or DV)\n",
    "feature_importances=lin_reg.coef_\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obviously, these 2 things will have the same length\n",
    "print(len(feature_importances))\n",
    "print(len(attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(x) for x in list(feature_importances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at the results\n",
    "feature_imp = pd.DataFrame(list(zip(attributes, feature_importances)), columns=['features', 'coeffs'])\n",
    "feature_imp=feature_imp.set_index('features')\n",
    "feature_imp=feature_imp.sort_values('coeffs')\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot that as a bar chart\n",
    "feature_imp.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with plotly\n",
    "import plotly.graph_objects as go\n",
    "data = go.Bar(x=list(feature_imp.index), y=feature_imp['coeffs'])\n",
    "fig = go.Figure([data])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show variables for a single observation:\n",
    "print(X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show scaled variables for that single observation:\n",
    "# Remember that we dropped the variable \"<1H OCEAN\"\n",
    "print(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on that:\n",
    "lin_reg.predict([X_train_scaled[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make up some fake data that's similar\n",
    "fake = np.array([-122, 37, 40, 2000, 3000, 500, 3, 3, 6, 4, 0, 0, 1, 0]).reshape(1, -1)\n",
    "fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize using the trained scaler\n",
    "std_fake = std_scaler.transform(fake)\n",
    "std_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a prediction for that observation:\n",
    "lin_reg.predict(std_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on your testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing dataset\n",
    "y_preds = lin_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine your predictions\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do the first five predictions compare to the first five actual values?\n",
    "true_5=list(round(y_test[:5], 1))\n",
    "pred_5=[round(x,1) for x in list(y_preds[:5])]\n",
    "print('true values:', true_5)\n",
    "print('predicted values:', pred_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we intepret those results?\n",
    "first_5=['district0', 'district1', 'district2', 'district3', 'distict4']\n",
    "pd.DataFrame(list(zip(first_5, true_5, pred_5)), columns=['district', 'true', 'predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error represents the average error (in $) of our model\n",
    "rmse_ols = np.sqrt(metrics.mean_squared_error(y_test, y_preds))\n",
    "rmse_ols = int(rmse_ols)\n",
    "rmse_ols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does this compare to a coinflip (i.e., the mean of our training set)?\n",
    "avg_val = round(y_train.mean(),2)\n",
    "avg_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we used that as our predictor, then the average error (RMSE) of our model would be:\n",
    "coinflip_preds=np.full((len(y_test), ), avg_val)\n",
    "rmse_coinflip=np.sqrt(metrics.mean_squared_error(y_test, coinflip_preds))\n",
    "rmse_coinflip=int(rmse_coinflip)\n",
    "rmse_coinflip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared is the proportion of the variance in the DV that's explained by the model\n",
    "r2_ols=metrics.r2_score(y_test, y_preds)\n",
    "r2_ols=round(r2_ols, 2)\n",
    "r2_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does this compare to a coinflip (i.e., the mean of our training set)?\n",
    "r2_coinflip=metrics.r2_score(y_test, coinflip_preds)\n",
    "r2_coinflip=round(r2_coinflip,2)\n",
    "r2_coinflip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the evaluation comparison as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare OLS Linear Regression to the Baseline\n",
    "\n",
    "evaluation_df = pd.DataFrame([['Baseline',rmse_coinflip, r2_coinflip], \n",
    "                              ['OLS Linear Regression', rmse_ols, r2_ols]], \n",
    "                             columns=['Model','RMSE','R-squared']\n",
    "                            )\n",
    "evaluation_df.set_index('Model', inplace=True)\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart with plotly: RMSE\n",
    "import plotly.graph_objects as go\n",
    "trace = go.Bar(x=list(evaluation_df.index), y=evaluation_df['RMSE'], marker=dict(color=['#E53712', '#1247E5']))\n",
    "layout = go.Layout(title = 'Median House Value by District: Root Mean Squared Error', # Graph title\n",
    "    yaxis = dict(title = 'Models'), # x-axis label\n",
    "    xaxis = dict(title = 'RMSE'), # y-axis label  \n",
    "                  ) \n",
    "\n",
    "fig = go.Figure(data = [trace], layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart with plotly: RMSE\n",
    "import plotly.graph_objects as go\n",
    "trace = go.Bar(x=list(evaluation_df.index), y=evaluation_df['R-squared'], marker=dict(color=['#E53712', '#1247E5']))\n",
    "layout = go.Layout(title = 'Median House Value by District: R-squared', # Graph title\n",
    "    yaxis = dict(title = 'Models'), # x-axis label\n",
    "    xaxis = dict(title = 'R-Squared'), # y-axis label  \n",
    "                  ) \n",
    "\n",
    "fig = go.Figure(data = [trace], layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation as a scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our true vs. predicted values\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Median House Value by District')\n",
    "plt.ylabel('True Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "fig=sns.regplot(x=y_preds, y=y_test)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing with plotly\n",
    "import plotly.express as px\n",
    "fig = px.scatter(y=y_test, x=y_preds, trendline=\"ols\", width=500, height=500)\n",
    "fig.update_layout(title = 'Median House Value by District', # Graph title\n",
    "    yaxis = dict(title = 'True values'), # x-axis label\n",
    "    xaxis = dict(title = 'Predicted values'), # y-axis label   \n",
    ")\n",
    "fig.update_traces(line_color='#E53712', line_width=5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out some other regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model\n",
    "from sklearn import linear_model\n",
    "# Create a local instance of the sklearn class\n",
    "ridge_model = linear_model.Ridge(alpha=.5)\n",
    "# Fit your instance to the training dataset\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the testing dataset\n",
    "y_preds = ridge_model.predict(X_test_scaled)\n",
    "# root mean squared error represents the average error (in $) of our model\n",
    "ridge_rmse = int(np.sqrt(metrics.mean_squared_error(y_test, y_preds)))\n",
    "# R-squared is the proportion of the variance in the DV that's explained by the model\n",
    "ridge_r2=round(metrics.r2_score(y_test, y_preds),2)\n",
    "print(ridge_rmse, ridge_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Create a local instance of the sklearn class\n",
    "knn_model = KNeighborsRegressor(n_neighbors=8)\n",
    "# Fit your instance to the training dataset\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the testing dataset\n",
    "y_preds = knn_model.predict(X_test_scaled)\n",
    "# root mean squared error represents the average error (in $) of our model\n",
    "knn_rmse = int(np.sqrt(metrics.mean_squared_error(y_test, y_preds)))\n",
    "# R-squared is the proportion of the variance in the DV that's explained by the model\n",
    "knn_r2=round(metrics.r2_score(y_test, y_preds),2)\n",
    "print(knn_rmse, knn_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Create a local instance of the sklearn class\n",
    "tree_model = DecisionTreeRegressor(max_depth=9)\n",
    "# Fit your instance to the training dataset\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the testing dataset\n",
    "y_preds = tree_model.predict(X_test_scaled)\n",
    "# root mean squared error represents the average error (in $) of our model\n",
    "tree_rmse = int(np.sqrt(metrics.mean_squared_error(y_test, y_preds)))\n",
    "# R-squared is the proportion of the variance in the DV that's explained by the model\n",
    "tree_r2=round(metrics.r2_score(y_test, y_preds),2)\n",
    "print(tree_rmse, tree_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create a local instance of the sklearn class\n",
    "forest_model = RandomForestRegressor(max_depth=10, n_estimators=200)\n",
    "# Fit your instance to the training dataset\n",
    "forest_model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the testing dataset\n",
    "y_preds = forest_model.predict(X_test_scaled)\n",
    "# root mean squared error represents the average error (in $) of our model\n",
    "forest_rmse = int(np.sqrt(metrics.mean_squared_error(y_test, y_preds)))\n",
    "# R-squared is the proportion of the variance in the DV that's explained by the model\n",
    "forest_r2=round(metrics.r2_score(y_test, y_preds),2)\n",
    "print(forest_rmse, forest_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the evaluation comparison as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare OLS Linear Regression to the Baseline\n",
    "\n",
    "evaluation_df2 = pd.DataFrame([['Baseline',rmse_coinflip, r2_coinflip], \n",
    "                              ['OLS Linear Regression', rmse_ols, r2_ols],\n",
    "                              ['Ridge Regession', ridge_rmse, ridge_r2],\n",
    "                              ['K-Nearest Neighbors Regression', knn_rmse, knn_r2],\n",
    "                              ['Decision Tree Regression', tree_rmse, tree_r2],\n",
    "                              ['Random Forest Regression', forest_rmse, forest_r2]], \n",
    "                             columns=['Model','RMSE','R-squared']\n",
    "                            )\n",
    "evaluation_df2.set_index('Model', inplace=True)\n",
    "evaluation_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart with plotly: RMSE\n",
    "import plotly.graph_objects as go\n",
    "trace = go.Bar(x=list(evaluation_df2.index), \n",
    "               y=evaluation_df2['RMSE'], \n",
    "               marker=dict(color=['#ebc83d','#badf55', '#35b1c9','#b06dad','#e96060', '#1e1d69']),\n",
    "#               plot_bgcolor='rgb(10,10,10)'\n",
    "              )\n",
    "layout = go.Layout(title = 'Model Comparison: Root Mean Squared Error', # Graph title\n",
    "    yaxis = dict(title = 'Models'), # x-axis label\n",
    "    xaxis = dict(title = 'RMSE'), # y-axis label  \n",
    "                  ) \n",
    "\n",
    "rmse_fig = go.Figure(data = [trace], layout=layout)\n",
    "rmse_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart with plotly: R-Squared\n",
    "import plotly.graph_objects as go\n",
    "trace = go.Bar(x=list(evaluation_df2.index), \n",
    "               y=evaluation_df2['R-squared'], \n",
    "               marker=dict(color=['#ebc83d','#badf55', '#35b1c9','#b06dad','#e96060', '#1e1d69']),\n",
    "#               plot_bgcolor='rgb(10,10,10)'\n",
    "              )\n",
    "layout = go.Layout(title = 'Model Comparison: R-Squared', # Graph title\n",
    "    yaxis = dict(title = 'Models'), # x-axis label\n",
    "    xaxis = dict(title = 'R-Squared'), # y-axis label  \n",
    "                  ) \n",
    "\n",
    "r2_fig = go.Figure(data = [trace], layout=layout)\n",
    "r2_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all outputs for visualization in Dash app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the figures\n",
    "with open('model_components/rmse_fig.pkl', 'wb') as handle:\n",
    "    pickle.dump(rmse_fig, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the figures\n",
    "with open('model_components/r2_fig.pkl', 'wb') as handle:\n",
    "    pickle.dump(r2_fig, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the standard scaler\n",
    "with open('model_components/std_scaler.pkl', 'wb') as handle:\n",
    "    pickle.dump(std_scaler, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store regression model \n",
    "import pickle\n",
    "with open('model_components/lin_reg.pkl', 'wb') as handle:\n",
    "    pickle.dump(lin_reg, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-open those pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_components/rmse_fig.pkl', 'rb') as f:\n",
    "    reopen_fig1=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reopen_fig1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
